{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "To use MKL 2018 with Theano you MUST set \"MKL_THREADING_LAYER=GNU\" in your environement.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\configparser.py\u001b[0m in \u001b[0;36m_unify_values\u001b[1;34m(self, section, vars)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m             \u001b[0msectiondict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'blas'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoSectionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\configparser.py\u001b[0m in \u001b[0;36mfetch_val_for_key\u001b[1;34m(key, delete_key)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtheano_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpolationError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\configparser.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m             \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unify_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\configparser.py\u001b[0m in \u001b[0;36m_unify_values\u001b[1;34m(self, section, vars)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msection\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_section\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1142\u001b[0m         \u001b[1;31m# Update with the entry specific variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSectionError\u001b[0m: No section: 'blas'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\configparser.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, cls, type_, delete_key)\u001b[0m\n\u001b[0;32m    327\u001b[0m                 val_str = fetch_val_for_key(self.fullname,\n\u001b[1;32m--> 328\u001b[1;33m                                             delete_key=delete_key)\n\u001b[0m\u001b[0;32m    329\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_default\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\configparser.py\u001b[0m in \u001b[0;36mfetch_val_for_key\u001b[1;34m(key, delete_key)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mConfigParser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoOptionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoSectionError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'blas.ldflags'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4583bf778b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprinting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m from theano.scan_module import (scan, map, reduce, foldl, foldr, clone,\n\u001b[0m\u001b[0;32m    125\u001b[0m                                 scan_checkpoints)\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\scan_module\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0m__contact__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Razvan Pascanu <r.pascanu@gmail>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_opt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_checkpoints\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_checkpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\scan_module\\scan_opt.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_scalar_constant_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAlloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAllocEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\tensor\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopt_uncanonicalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mblas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mblas_scipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mblas_c\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\tensor\\blas.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbasic\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblas_headers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mblas_header_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblas_headers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mblas_header_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0min2out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_dimshuffle_lift\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\tensor\\blas_headers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mldflags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m     \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using NumPy C-API based implementation for BLAS functions.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\configparser.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, cls, type_, delete_key)\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m                     \u001b[0mval_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     \u001b[0mval_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\configdefaults.py\u001b[0m in \u001b[0;36mdefault_blas_ldflags\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'mkl'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                 \u001b[0mcheck_mkl_openmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1431\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\theano\\configdefaults.py\u001b[0m in \u001b[0;36mcheck_mkl_openmp\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mmkl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'2018'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_version_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'To use MKL 2018 with Theano you MUST set \"MKL_THREADING_LAYER=GNU\" in your environement.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m         raise RuntimeError(\"\"\"\n",
      "\u001b[1;31mRuntimeError\u001b[0m: To use MKL 2018 with Theano you MUST set \"MKL_THREADING_LAYER=GNU\" in your environement."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#%pylab\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style \n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = np.loadtxt('../data/ex2data1.txt', delimiter=',', dtype='float32')\n",
    "X = data[:, [0, 1]]\n",
    "Y= data[:, 2]\n",
    "m = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "pos = plt.scatter(X[Y == 1, 0], X[Y == 1, 1], s=32, c='red', marker='x')\n",
    "neg = plt.scatter(X[Y == 0, 0], X[Y == 0, 1], s=32, c='yellow', marker='o')\n",
    "plt.xlabel('Exam 1 score')\n",
    "plt.ylabel('Exam 2 score')\n",
    "# Isso adiciona atraso à dispersão\n",
    "plt.legend((pos, neg), ('Admitted', 'Not admitted'), scatterpoints=1, loc='lower left', ncol=1, fontsize=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione uma coluna 1 no X\n",
    "XTemp = np.ones([m,3], dtype='float32')\n",
    "XTemp[:, [1, 2]] = X\n",
    "X = XTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmod function\n",
    "\n",
    "$$ g(z) = \\frac {1} { 1 + e ^ {-z} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + T.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "hypothesis\n",
    "\n",
    "$$ h _ { \\theta } (x) = g ( \\theta ^ Tx ) $$\n",
    "\n",
    "loss function\n",
    "\n",
    "$$ J ( \\theta ) = \\frac {1} {m} \\sum{ i=1 } ^ {m} \\left[ - y^ { (i) } \\log ( h{ \\theta } ( x ^ { (i) } ) ) - (1 - y^{ (i) } ) \\log ( 1 - h_{ \\theta } ( x ^ { (i) } ) ) \\right] $$ \n",
    "\n",
    "Derivação da função de perda de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloque os dados de treinamento em gpu (100, 3) \n",
    "x = theano.shared(X, name='x')  \n",
    "# (100, )\n",
    "y = theano.shared(Y, name='y')  \n",
    "theta = theano.shared(np.zeros([3, 1], dtype='float32'), name='theta')\n",
    "# Taxa de aprendizagem\n",
    "alpha = T.scalar('alpha') \n",
    "# (100, 1)\n",
    "pre_prob = sigmoid(x.dot(theta)) \n",
    "# y precisa ser vetor, precisa de dimshuffle\n",
    "loss = T.mean(-y.dimshuffle(0, 'x') * T.log(pre_prob) - (1- y.dimshuffle(0, 'x')) * T.log(1 - pre_prob)) \n",
    "calcLoss = theano.function([], loss)\n",
    "# Calcular a precisão da classificação\n",
    "precision = theano.function([], T.eq(T.ge(pre_prob, 0.5), y.dimshuffle(0, 'x')).sum() / T.cast(x.shape[0], 'float32')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient w.s.t theta\n",
    "\n",
    "$$ \\frac{ \\partial { J ( \\theta ) } } { \\partial { \\thetaj } } = \\frac {1} {m} \\sum{ i = 1} ^ {m} \\left ( h_{ \\theta } (x^{ (i) } ) - y^{ (i) } \\right ) x_j^{ (i) } $$\n",
    "\n",
    "update theta with gradient descent\n",
    "\n",
    "$$ \\theta = \\theta - \\alpha \\nabla \\theta $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente\n",
    "grad_all = T.mean((pre_prob - y.dimshuffle(0, 'x')).repeat(3, 1) * x, axis=0)  \n",
    "# Gradiente descendente\n",
    "gradient_step_all = theano.function([alpha],updates={theta : theta - alpha * grad_all.dimshuffle(0, 'x')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente automaticamente\n",
    "grad_auto = T.grad(loss, theta) \n",
    "gradient_step_auto = theano.function([alpha],updates={theta : theta - alpha * grad_auto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calcLoss()) \n",
    "print(grad_all.eval({})) \n",
    "print(grad_auto.eval({})) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento de otimização de descida de gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu 39.1s, gpu (meio lento...)\n",
    "startTime = time.time() \n",
    "# Treinamento, ajuste dinâmico de gradientes\n",
    "theta.set_value(np.zeros([3, 1], dtype='float32'))\n",
    "max_iters = 100000\n",
    "alpha = 0.1\n",
    "best_loss = np.Inf\n",
    "best_theta = theta.get_value()\n",
    "J_history = np.zeros((max_iters, 1))\n",
    "for i in range(max_iters):\n",
    "    theta.set_value(best_theta)\n",
    "    gradient_step_auto(alpha)\n",
    "    tempLoss = calcLoss()\n",
    "    J_history[i] = tempLoss\n",
    "    if tempLoss < best_loss:\n",
    "        best_loss = tempLoss\n",
    "        best_theta = theta.get_value()\n",
    "    else:\n",
    "        alpha = alpha * 0.99\n",
    "endTime = time.time()\n",
    "print(theta.get_value()) \n",
    "print('training cost %.1fs' % (endTime - startTime)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use o módulo de otimização do scipy para treinamento de otimização e demonstre dinamicamente o processo iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o custo para o teta especificado Ao usar a função de otimização, o parâmetro a ser otimizado \n",
    "# é um vetor unidimensional, portanto, para converter em um vetor de coluna bidimensional, e ao usar fmin \n",
    "# também precisa ser convertido para o tipo float32\n",
    "def computeCost(theta_value):\n",
    "    theta.set_value(theta_value.reshape(3,1).astype('float32'))\n",
    "    return calcLoss()\n",
    "\n",
    "# Calcular o gradiente ao especificar teta\n",
    "calcGrad= theano.function([], grad_auto)\n",
    "def train_fn_grad(theta_value):\n",
    "    theta.set_value(theta_value.reshape(3,1).astype('float32'))\n",
    "    return np.array(calcGrad().reshape(3)) # O gradiente também deve ser convertido em vetor unidimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "from scipy import optimize\n",
    "# Armazene o resultado após cada iteração\n",
    "thetaV = [] \n",
    "def optimizeTheta():\n",
    "    # Uma forma vetorial unidimensional de x0 passou para theta\n",
    "    # Use fmin para encontrar a solução ideal, usando Nelder-Mead (método simplista)\n",
    "    result = optimize.fmin(computeCost, x0=np.zeros(3, dtype=theano.config.floatX), maxiter=1000, \n",
    "                           full_output=True, callback=lambda t : thetaV.append(t.reshape(3, 1)))     \n",
    "    return result[0], result[1]\n",
    "thetaValue, mincost = optimizeTheta()\n",
    "print(thetaValue) \n",
    "\n",
    "# Processo iterativo de demonstração animada\n",
    "# Dinamicamente traçar limites de decisão\n",
    "def plotDecisionBoundaryAnimation(i): \n",
    "    # Desenhar pontos de dados primeiro\n",
    "    fig.clear()\n",
    "    pos = plt.scatter(X[Y == 1, 1], X[Y == 1, 2], s=32, c='red', marker='x')\n",
    "    neg = plt.scatter(X[Y == 0, 1], X[Y == 0, 2], s=32, c='yellow', marker='o')\n",
    "    plt.xlabel('Exam 1 score')\n",
    "    plt.ylabel('Exam 2 score')\n",
    "    # Isso adiciona atraso à dispersão\n",
    "    plt.legend((pos, neg), ('Admitted', 'Not admitted'), scatterpoints=1, loc='lower left', ncol=1, fontsize=12) \n",
    "    # Traçar limites de decisão\n",
    "    plot_x = [X[:, 1].min() - 2, X[:, 1].max() + 2]\n",
    "    plot_y = -(thetaV[i][1] * plot_x + thetaV[i][0]) / thetaV[i][2]\n",
    "    plt.plot(plot_x, plot_y)\n",
    "\n",
    "# Processo de otimização iterativa de demonstração dinâmica\n",
    "fig = plt.figure() \n",
    "# call animate desenho a cada 10ms\n",
    "ani = animation.FuncAnimation(fig, plotDecisionBoundaryAnimation, frames=len(thetaV), interval = 1) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a otimização de função mínima, somente o Nelder-Mead pode encontrar a solução ideal.\n",
    "result = optimize.minimize(computeCost, np.zeros(3, dtype=theano.config.floatX),  method='Nelder-Mead', options={\"maxiter\":500, \"disp\":True} )\n",
    "thetaValue, mincost = np.array([result.x]), result.fun\n",
    "print(thetaValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use os parâmetros calculados para classificar e encontrar a precisão da classificação\n",
    "theta.set_value(thetaValue.reshape(3, 1).astype('float32')) # Definir o valor de theta\n",
    "precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a otimização do gradiente conjugado, relatou nan\n",
    "thetaValue = optimize.fmin_cg(\n",
    "    f=computeCost,\n",
    "    x0=np.random.rand(3,1),\n",
    "    fprime=train_fn_grad,\n",
    "    disp=1,\n",
    "    maxiter=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar resultados de matlab\n",
    "%matplotlib inline\n",
    "def plotDecisionBoundary(theta, X, Y): # Traçar limites de decisão\n",
    "    # Desenhar pontos de dados primeiro\n",
    "    fig = plt.figure()\n",
    "    pos = plt.scatter(X[Y == 1, 1], X[Y == 1, 2], s=32, c='red', marker='x')\n",
    "    neg = plt.scatter(X[Y == 0, 1], X[Y == 0, 2], s=32, c='yellow', marker='o')\n",
    "    plt.xlabel('Exam 1 score')\n",
    "    plt.ylabel('Exam 2 score')\n",
    "    # Isso adiciona atraso à dispersão\n",
    "    plt.legend((pos, neg), ('Admitted', 'Not admitted'), scatterpoints=1, loc='lower left', ncol=1, fontsize=12) \n",
    "    # Traçar limites de decisão\n",
    "    plot_x = [X[:, 1].min() - 2, X[:, 1].max() + 2]\n",
    "    plot_y = -(theta[1] * plot_x + theta[0]) / theta[2]\n",
    "    plt.plot(plot_x, plot_y)\n",
    "    \n",
    "# Este é o resultado do matlab usando otimização fminunc\n",
    "plotDecisionBoundary(np.array([[-24.932998460539014],[0.204407718945030],[0.199618080892081]]), X, Y) \n",
    "plotDecisionBoundary(theta.get_value(), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence graph\n",
    "fig = plt.figure() \n",
    "plt.plot(np.arange(max_iters) + 1, J_history)\n",
    "plt.xlim(0, 3000)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Cost J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o sklearn para treinar modelos de regressão logística\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "lr = LogisticRegression(solver='newton-cg') # ou use liblinear...\n",
    "lr.fit(X,Y) # Treinamento\n",
    "print((lr.predict(X) == Y).sum()/100.0) # Precisão\n",
    "print(lr.coef_) # Coeficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivação da função de perda de regressão logística\n",
    "\n",
    "Como o domínio da função sigmóide é $ ( -\\infty , + \\infty ) $, o alcance é $ ( 0 , 1 ) $，ela pode ser vista como uma representação de probabilidade, considerando a função sigmóide como a função de densidade de probabilidade dos dados da amostra, e para cada ponto de amostragem, sua densidade de probabilidade pode ser calculada pela função sigmóide.\n",
    "\n",
    "Considere $x$ 具vector com p variáveis independentes $ x^T = ( x_1 , x_2 , \\cdots , xp ) $，probabilidade condicional $ P ( Y=1 \\mid x ; \\theta ) = p $ por um dado $x$，$Y = 1$ A probabilidade. O modelo de regressão logística pode ser expresso como: $$ \\begin{align} & h{ \\theta } (x) = \\frac {1} { 1 + e^{ - \\theta^Tx } } \\notag \\ & P ( Y = 1 \\mid x ; \\theta ) = h{ \\theta } (x) \\notag \\ & P ( Y = 0 \\mid x; \\theta) = 1 - h{ \\theta } (x) \\notag \\end{align} $$\n",
    "Suponha que existem n amostras de observação, e os valores de observação são $ y_1 , y_2 , \\cdots , y_n $，configurar $ p_i = P ( y^{ (i) } = 1 \\mid x^{ (i) } : \\theta ) $ obtido por uma determinada condição $ y_i = 1 $ a probabilidade é obtida sob as mesmas condições $ y_i = 0 $ a probabilidade condicional é $ P( y^{ (i) } = 0 \\mid x^{ (i) } : \\theta ) = 1 - p_i $ . Assim, a probabilidade de obter uma observação é: $$ \\begin{align} P(y_i) &= p_i^{ y^{ (i) } } ( 1 - pi )^{ 1 - y^{ (i) } } \\notag \\ &= \\left ( h{\\theta} (x^{ (i) }) \\right )^{ y^{ (i) } } \\left( 1 - h{\\theta} (x^{ (i) }) \\right )^{1- y^{ (i) } } \\notag \\end{align} $$\n",
    "Como as observações são independentes, sua distribuição conjunta pode ser expressa como o produto das distribuições marginais: $$ \\begin{align} L ( \\theta ) &= p( \\vec y \\mid X ; \\theta ) \\notag \\ &= \\prod{i=1}^n p \\left ( y^{(i)} \\mid x^{(i)} ; \\theta \\right ) \\notag \\ &= \\prod{i=1}^n \\left ( h{\\theta} (x^{(i)}) \\right )^{ y^{(i)} } \\left( 1 - h{\\theta} (x^{(i)}) \\right )^{1- y^{(i)} } \\notag \\end{align} $$\n",
    "A fórmula acima é chamada n funções de verossimilhança observadas. Nosso objetivo é ser capaz de encontrar estimativas de parâmetros que maximizem o valor dessa função de verossimilhança. Então, a chave para a estimativa da máxima verossimilhança é encontrar os parâmetros $\\theta$，Deixe a fórmula obter o valor máximo.\n",
    "\n",
    "Encontre o logaritmo da função acima:\n",
    "$$ \\begin{align} \\ell ( \\theta ) &= \\log L( \\theta ) \\notag \\ &= \\sum{ i = 1 }^n y^{(i)} \\log h( x^{(i)} ) + ( 1 - y^{(i)}) \\log ( 1 - h ( x^{(i)} ) ) \\notag \\end{align} $$\n",
    "Depois de tirar o negativo, é precisamente para minimizar a entropia cruzada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
