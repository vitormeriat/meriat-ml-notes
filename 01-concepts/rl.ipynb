{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear\n",
    "\n",
    "Vamos supor que tenhamos dados em tabela sobre duas variáveis: **x** e **y**. Se colocarmos cada par **(x,y)** em um gráfico, teremos uma figura como a seguinte:\n",
    "\n",
    "![1](https://matheusfacure.github.io/img/tutorial/regr_lin_mqo/scatter.png)\n",
    "\n",
    "O que o algoritmo de regressão linear faz é simplesmente achar a reta que melhor se encaixa entre os pontos:\n",
    "\n",
    "Assim, podemos prever (com erro) um valor de y dado um valor de x. Por exemplo, nós não temos uma observação em que x=1, mas gostaríamos de prever qual seria o valor de y caso x fosse 1. Basta então olhar na linha qual valor de y quando x assume o valor 1. Na imagem acima, y seria aproximadamente 2.5 (ponto amarelo).\n",
    "\n",
    "![2](https://matheusfacure.github.io/img/tutorial/regr_lin_mqo/scatter_line.png)\n",
    "\n",
    "Ok. Esse exemplo é bem simples e meramente ilustrativo. Suponha agora que y não dependa mais apenas de x, mas de x e z. Bem, nesse caso, teríamos um gráfico em 3D e a regressão linear acharia o plano que melhor se encaixa nos dados. E para mais dimensões? Digamos que y dependa de 100 variáveis. Nós não podemos mais visualizar esse caso, mas sabemos que não é muito diferente dos casos 2D ou 3D, só que agora a regressão linear acha o hiperplano que melhor se encaixa nos dados. Se isso está um pouco abstrato e difícil de visualizar, pense  sempre em 3D quando trabalhando com muitas dimensões. É um truque muito útil que eu aprendi em um vídeo do professor de Geoffrey Hinton e, segundo ele, todo mundo faz isso: quando tentar visualizar 100 dimensões, por exemplo, pense em 3D e grite para si mesmo \"100D\" e você conseguirá abstrair grandes dimensionalidades.\n",
    "\n",
    "### Justificativa matemática\n",
    "Imagine que temos dados em tabela, sendo que cada linha é uma observação e cada coluna uma variável. Então escolhemos uma das colunas para ser nossa variável dependente y (aquela que queremos prever) e as outras serão as variáveis independentes (X). Nosso objetivo é aprender como chegar das variáveis independentes na variável dependente, ou, em outras palavras, prever y a partir de X. Note que X é uma matriz nxd, em que n é o número de observações e d o número de dimensões; y é um vetor coluna nx1. Podemos definir o problema como um sistema de equações em que cada equação é uma observação:\n",
    "\n",
    "$\\begin{cases}\n",
    "w_0 + w_1 x_1 + ... + w_d x_1 = y_1 \\\\\n",
    "w_0 + w_1 x_2 + ... + w_d x_2 = y_2 \\\\\n",
    "... \\\\\n",
    "w_0 + w_1 x_n + ... + w_d x_n = y_n \\\\\n",
    "\\end{cases}$\n",
    "\n",
    "Normalmente $n > d$, isto é, temos mais observações que dimensões. Sistemas assim costumam não ter solução, pois há muitas equações e poucas variáveis para ajustar. Intuitivamente, pense que, na prática, muitas coisas afetam a variável y, principalmente se ela for algo de interesse das ciências humanas como, por exemplo, preço, desemprego, felicidade etc. Muitas das coisas que afetam y não podem ser coletadas como dados; desse modo, as equações acima não teriam solução porque não teríamos todos os fatores que afetam y.\n",
    "\n",
    "Para lidar com esse problema, vamos adicionar nas equações um termo erro ε que representará os fatores que não conseguimos observar, erros de medição, etc.\n",
    "\n",
    "$\\begin{cases}\n",
    "w_0 + w_1 x_{11} + ... + w_d x_{1d} + \\varepsilon_1 = y_1 \\\\\n",
    "w_0 + w_1 x_{21} + ... + w_d x_{2d} + \\varepsilon_2 = y_2 \\\\\n",
    "... \\\\\n",
    "w_0 + w_1 x_{n1} + ... + w_d x_{nd} + \\varepsilon_3 = y_n \\\\\n",
    "\\end{cases}$\n",
    "\n",
    "Ou, em forma de matriz:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & x_{11} & ... & x_{1d} \\\\\n",
    "1 & x_{21} & ... & x_{2d} \\\\\n",
    "\\vdots & \\vdots& \\vdots & \\vdots \\\\\n",
    "1 & x_{n1} & ... & x_{nd} \\\\\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "w_0 \\\\\n",
    "w_1 \\\\\n",
    "\\vdots \\\\\n",
    "w_d \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "\\varepsilon_0 \\\\\n",
    "\\varepsilon_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\varepsilon_n \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "y_0 \\\\\n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_n \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$X_{nd} \\pmb{w}_{d1} + \\pmb{\\epsilon}_{n1} = \\pmb{y}_{n1}$\n",
    "\n",
    "Para estimar a equação acima, usaremos a técnica de Mínimos Quadrados Ordinários (MQO): queremos achar os $\\pmb{\\hat{w}}$  que minimizam os $n \\varepsilon^2$, ou, na forma de vetor, $\\pmb{\\epsilon}^T \\pmb{\\epsilon}$. Por que minimizar os erros quadrados? Assim como todo algoritmo de Aprendizado de Máquina, regressão linear também pode ser encarada como problemas de minimização de função custo. Então, nesse caso, nossa função custo é $L = \\pmb{\\epsilon}^T \\pmb{\\epsilon}$. Um nome comum dessa função é o custo quadrático $L2$, pois nesse caso o custo é o quadrado da norma $L2$ do vetor $\\pmb{\\epsilon}$. Note que nós poderíamos usar também a norma $L1$ do mesmo vetor como função custo. Ou ainda, poderíamos usar outras funções que adicionam uma penalidade também para o tamanho de $\\pmb{\\hat{w}}$, como acontece nos algoritmos de regressão Ridge ou Lasso, mas isso terá que ficar para outro tutorial. Por hora, a soma dos mínimos quadrados bastará como função custo, até porque ela tem a vantagem de deixar a matemática muito mais simples:\n",
    "\n",
    "$\\pmb{\\epsilon}^T  \\pmb{\\epsilon} = (\\pmb{y} - \\pmb{\\hat{w}}X)^T(\\pmb{y} - \\pmb{\\hat{w}} X) \\\\= \\pmb{y}^T \\pmb{y} - \\pmb{\\hat{w}}^T X^T \\pmb{y} - \\pmb{y}^T X \\pmb{\\hat{w}} + \\pmb{\\hat{w}} X^T X \\pmb{\\hat{w}} \\\\= \\pmb{y}^T \\pmb{y} - 2\\pmb{\\hat{w}}^T X^T \\pmb{y} + \\pmb{\\hat{w}} X^T X \\pmb{\\hat{w}}$\n",
    "\n",
    "![]()\n",
    "\n",
    "![]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # para ler os dados em tabela\n",
    "import numpy as np # para álgebra linear\n",
    "from sklearn import linear_model, model_selection, datasets\n",
    "import matplotlib.pyplot as plt # para fazer gráficos\n",
    "from matplotlib import style\n",
    "from time import time # para ver quanto tempo demora\n",
    "np.random.seed(1) # para resultados consistentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class linear_regr(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # adiciona coluna de 1 nos dados\n",
    "        X = np.insert(X_train, 0, 1, 1)\n",
    "\n",
    "        # estima os w_hat\n",
    "        # (X^T * X)^-1 * X^T * y\n",
    "        w_hat = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y_train)\n",
    "\n",
    "        self.w_hat = w_hat\n",
    "        self.coef = self.w_hat[1:]\n",
    "        self.intercept = self.w_hat[0]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X = np.insert(X_test, 0, 1, 1) # adiciona coluna de 1 nos dados\n",
    "        y_pred = np.dot(X, self.w_hat) # X * w_hat = y_hat\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9LoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1082dbc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#read data\n",
    "dataframe = pd.read_fwf('brain_body.txt')\n",
    "x_values = dataframe[['Brain']]\n",
    "y_values = dataframe[['Body']]\n",
    "\n",
    "#train model on data\n",
    "body_reg = linear_model.LinearRegression()\n",
    "body_reg.fit(x_values, y_values)\n",
    "\n",
    "#visualize results\n",
    "plt.scatter(x_values, y_values)\n",
    "plt.plot(x_values, body_reg.predict(x_values))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brain</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.385</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.350</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465.000</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.330</td>\n",
       "      <td>119.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brain   Body\n",
       "0    3.385   44.5\n",
       "1    0.480   15.5\n",
       "2    1.350    8.1\n",
       "3  465.000  423.0\n",
       "4   36.330  119.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separa em bases de treino e teste\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(x_values, y_values, test_size = 0.3, random_state = 1)\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2, 43), indices imply (1, 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4293\u001b[0m                 blocks = [make_block(values=blocks[0],\n\u001b[0;32m-> 4294\u001b[0;31m                                      placement=slice(0, len(axes[0])))]\n\u001b[0m\u001b[1;32m   4295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[1;32m    114\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[0;32m--> 115\u001b[0;31m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-49600b042641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tempo do criado manualmente:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7f79cbbb420f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# adiciona coluna de 1 nos dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# estima os w_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   4914\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4915\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4916\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4917\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 306\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4301\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4303\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitormeriat/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4279\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 4280\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (2, 43), indices imply (1, 43)"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "regr = linear_regr()\n",
    "regr.fit(X_train, y_train)\n",
    "print(\"Tempo do criado manualmente:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# medindo os erros\n",
    "y_hat = regr.predict(X_test) # prevendo os preços\n",
    "\n",
    "print('Média do erro absoluto: ', np.absolute((y_hat - y_test)).mean())\n",
    "print('Média do erro relativo: ', np.absolute(((y_hat - y_test) / y_test)).mean())\n",
    "\n",
    "# comparando com o de mercado\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "print(\"\\n\\nTempo do de mercado:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# medindo os erros\n",
    "y_hat = regr.predict(X_test) # prevendo os preços\n",
    "w_hat = regr.intercept_\n",
    "w_hat = np.append(w_hat, regr.coef_)\n",
    "\n",
    "print('Média do erro absoluto: ', np.absolute((y_hat - y_test)).mean())\n",
    "print('Média do erro relativo: ', np.absolute(((y_hat - y_test) / y_test)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
